# chapter 3 SLO工程案例研究

尽管 SRE 的许多原则都是在 Google 墙内形成的，但它的原则早已存在于我们的大门之外。 许多标准的 Google SRE 实践已经被并行发现，或者被整个行业的许多其他组织采用。

SLO 是 SRE 模型的基础。 自从我们启动了客户可靠性工程（CRE）团队 - 一组经验丰富的SRE，帮助 Google Cloud Platform（GCP）客户构建更可靠的服务 - 几乎每个客户交互都以 SLOs 开始和结束。

在这里，我们介绍了两个非常不同的公司讲述的故事，概述了他们在与 Google CRE 团队合作时采用 SLO 和基于错误预算的方法的过程。 有关SLO和错误预算的更一般性讨论，请参阅本书中的第 2 章和第一本书中的第 3 章。

## Evernote 的 SLO 故事

*作者：Ben McCormack，Evernote*

Evernote 是一款跨平台应用程序，可帮助个人和团队创建，组装和共享信息。 我们在全球拥有超过 2.2 亿用户，我们在平台内存储了超过 120 亿条信息 - 混合了基于文本的笔记，文件和附件/图像。 在幕后，Evernote 服务由 750 多个 MySQL 实例支持。

我们向 Evernote 引入了 SLO 的概念，作为更广泛的技术改造的一部分，旨在提高工程速度，同时保持服务质量。 包括我们的目标：

- 将工程重点从数据中心中无差别的繁重工作转移到客户实际关心的产品工程工作上。 为此，我们停止运行物理数据中心并转移到公共云。
- 修改操作和软件工程师的工作模型，以支持提高特征速度，同时保持整体服务质量。
- 改进我们对 SLAs 的看法，以确保我们更加关注故障如何影响我们庞大的全球客户群。

许多行业的组织可能都熟悉这些目标。 虽然没有一种简单的方法来进行这些类型的更改将全面运作，但我们希望分享我们的经验将为面临类似挑战的其他人提供有价值的见解。

### 为什么 Evernote 采用 SRE 模型？

在此过渡开始时，Evernote 的特点是传统的运维/开发分离：运维团队保护生产环境的神圣性，而开发团队的任务是为客户开发新的产品功能。 这些目标通常是冲突的：开发团队感到受到冗长的操作要求的限制，而当新代码在生产中引入新问题时，运维团队感到沮丧。 当我们在这两个目标之间疯狂地摇摆时，运维组和开发团队发展了一种沮丧和紧张的关系。 我们希望达到一种更快乐的媒介，更好地平衡所涉及团队的不同需求。

我们试图在五年多的时间里以各种方式解决传统二分法中的差距。 在尝试了“你编写它，运行它”（开发）模型，以及“你编写它，我们为你运行它”（运维）模型后，我们转向了以 SLO 为中心的 SRE 方法。

那么是什么促使 Evernote 向这个方向发展呢？

在 Evernote，我们将运维和开发的核心学科视为工程师可以专业化的独立专业轨道。 其中一条轨道涉及近乎全天候向客户提供服务。另一方面关注该服务的扩展和发展，以满足未来客户的需求。 近年来，这两个学科相互走向，因为像 SRE 和 DevOps 这样的改变强调软件开发应用于运维。（数据中心自动化的发展和公共云的发展进一步推动了这种融合，这两者都为我们提供了一个可以完全由软件控制的数据中心。）另一方面，全栈所有权和持续部署越来越多地应用于软件开发。

我们被 SRE 模型所吸引，因为它完全接受并接受了运维和开发之间的差异，同时鼓励团队朝着共同的目标努力。 它不会尝试将运维工程师转变为应用程序开发人员，反之亦然。 相反，它给出了一个共同的参考框架。 根据我们的经验，错误预算/ SLO 方法导致两个团队在提出相同事实时做出类似的决定，因为它从对话中消除了大量的主观性。

### SLO 简介：正在进行的旅程

我们旅程的第一部分是从物理数据中心迁移到 Google Cloud Platform。<sup>1</sup> 一旦 Evernote 服务在 GCP 上运行并稳定运行，我们就引入了 SLO。 我们的目标有两个：

- 使团队内部围绕 Evernote SLO，确保所有团队都在新框架内工作。
- 将 Evernote 的 SLO 纳入我们与 Google Cloud 团队合作的方式，他们现在负责我们的底层基础架构。 由于我们现在在整体模型中有了新的合作伙伴，因此我们需要确保迁移到 GCP 不会稀释或掩盖我们对用户的承诺。

在积极使用 SLO 约 9 个月后，Evernote 已经开始使用其 SLO 实践的第 3 版了！

在深入了解 SLO 的技术细节之前，从客户的角度开始转换是非常重要的：您想要坚持哪些承诺？ 与大多数服务类似，Evernote 具有许多功能和选项，我们的用户可以通过各种创造性方式使用这些功能和选项。我们希望确保我们最初关注最重要和最常见的客户需求：Evernote 服务的可用性，以便用户访问和同步多个客户端的内容。我们的 SLO 之旅从这个目标开始。通过关注正常运行时间，我们保持了第一次通过。使用这种简单的第一种方法，我们可以清楚地表达我们测量的内容以及测量方法。

> 1 但这是另一本书的故事 - 请参阅http://bit.ly/2spqgcl了解更多细节。

我们的第一份 SLO 文件包含以下内容：

*SLO的定义*

这是一个正常运行时间测量：在每月窗口中测量 99.95％ 的正常运行时间，为某些服务和方法设置。 我们根据与内部客户支持和产品团队的讨论以及更重要的用户反馈来选择此数字。 我们故意选择将我们的 SLO 绑定到一个日历月而不是滚动期，以便在运行服务评估时保持我们的专注和有条理。

*衡量什么，以及如何衡量它*

> 衡量什么
>> 我们指定了一个服务端点，我们可以调用它来测试服务是否按预期运行。在我们的例子中，我们的服务中内置了一个状态页面，它可以运行我们的大部分堆栈并返回 200 状态代码（如果一切正常）。
    
> 怎么衡量
>> 我们想要一个定期调用状态页面的探测器。 我们希望探测器完全位于我们的环境之外并独立于我们的环境，因此我们可以测试所有组件，包括我们的负载平衡堆栈。 我们的目标是确保我们测量 GCP 服务和 Evernote 应用程序的任何和所有故障。 但是，我们不希望随机互联网问题触发误报。 我们选择使用专门建立和运行此类探测器的第三方公司。 我们选择了 [Pingdom](https://www.pingdom.com/)，但市场上还有很多其他产品。 我们按如下方式进行测量：
>>- **探测频率**：我们每分钟轮询一次前端节点。
>>- **探测器的位置**：此设置是可配置的; 我们目前在北美和欧洲使用多个探头。
>>- **“down”的定义**：如果探测器检查失败，则节点标记为 Unconfirmed Down，然后第二个地理位置独立的探测器执行检查。 如果第二次检查失败，则将节点标记为 down 以进行 SLO 计算。 只要连续探测请求注册错误，节点将继续标记为 down。

*如何从监控数据计算 SLO*

最后，我们仔细记录了我们如何根据从 Pingdom 收到的原始数据计算 SLO。例如，我们指定了如何考虑维护窗口：我们无法假设我们所有的数亿用户都知道我们发布的维护窗口。 因此，不知情的用户会将这些窗口视为通用和无法解释的停机时间，因此我们的 SLO 计算将维护视为停机时间。

一旦我们定义了 SLO，我们就必须对它们做些什么。 我们希望 SLO 能够推动软件和运营方面的变革，让我们的客户更快乐并让他们满意。 怎么做到最好？

我们使用 SLO/错误预算 概念作为分配资源的方法。 例如，如果我们错过了上个月的 SLO，那么这种行为有助于我们优先考虑相关的修复，改进和错误修复。 我们保持简单：来自 Evernote 和 Google 的团队每月都会对 SLO 性能进行审核。 在本次会议上，我们将审查上个月的 SLO 绩效，并对任何停机进行深入研究。 基于对过去一个月的分析，我们设置了可能未通过常规根本原因分析过程捕获的改进的行动项目。

在整个过程中，我们的指导原则是“完美是善的敌人。”即使 SLO 不完美，它们也足以指导长期改进。 “完美” SLO 将衡量每个可能的用户与我们的服务的交互，并解决所有边缘情况。 虽然这在纸面上是个好主意，但要实现完美（如果达到完美程度）还需要几个月的时间 - 我们可以用来改善服务的时间。 相反，我们选择了一个初始 SLO，它涵盖了大多数（但不是全部）用户交互，这是服务质量的良好代理。

自从我们开始以来，我们根据内部服务评估和响应客户影响停机的信号，对我们的 SLO 进行了两次修改。 因为我们一开始并不是为了完美的 SLO，所以我们很乐意进行更改以更好地与业务保持一致。 除了我们每月的 Evernote / Google 对 SLO 性能的评估之外，我们还确定了一个为期六个月的 SLO 审核周期，它在经常更换 SLO 并让它们变得陈旧之间取得了适当的平衡。 在修改我们的 SLO 时，我们还了解到，平衡您想要衡量的内容与可能的衡量标准非常重要。

自引入 SLO 以来，我们的运维和开发团队之间的关系有了微妙但显着的改善。 这些团队现在有一个共同的成功衡量标准：消除人类对服务质量（QoS）的解释使得两个团队都能够保持相同的观点和标准。 举一个例子，SLO 提供了一个共同点，当时我们必须在 2017 年的压缩时间线中促进多个版本。虽然我们追查了一个复杂的错误，但产品开发要求我们在多个单独的窗口中分配我们正常的每周版本，每个窗口都会对客户产生影响。 通过对问题应用 SLO 计算并从场景中消除人体主观性，我们能够更好地量化客户影响并将我们的发布窗口从五个减少到两个，以最大限度地减少客户的痛苦。

### 打破客户与云提供商之间的 SLO 墙

客户和云提供商关注点之间的虚拟墙可能看似自然或不可避免。 虽然谷歌为 GCP 平台提供了 SLO 和 SLA（服务水平协议），但我们运行 Evernote，但 Evernote 拥有自己的 SLOs 和 SLAs。 并不总是期望两个这样的工程团队会被告知彼此的 SLAs。

Evernote 永远不会想要这样的墙。 当然，我们可以设计一个分隔墙，将我们的 SLO 和 SLA 建立在基础 GCP 指标上。 相反，从一开始，我们就希望 Google 了解哪些性能特征对我们最重要，以及为什么。 我们希望将 Google 的目标与我们的目标保持一致，并让两家公司将 Evernote 的可靠性成功和失败视为共同责任。 为实现这一目标，我们需要一种方法：

- 协调目标

- 确保我们的合作伙伴（在本例中为Google）真正了解对我们重要的内容

- 分享成功和失败

大多数服务提供商为其云服务管理已发布的 SLO/SLAs。 在此上下文中工作很重要，但它无法全面表示我们的服务在云提供商的环境中运行得如何。

例如，给定的云提供商可能在全球运行数十万个虚拟机，它们可以管理正常运行时间和可用性。GCP 承诺计算引擎（即其虚拟机）的可用性为 99.95％。 即使 GCP SLO 图表为绿色（即高于 99.95％），Evernote 对同一 SLO 的看法可能也大不相同：因为我们的虚拟机占用空间仅占全球 GCP 数量的一小部分，因此我们所在地区的隔离（或隔离） 由于其他原因）可能会在整体汇总到全局级别时“丢失”。

为了纠正这样的情况，我们与 Google 分享 SLO 和 SLO 的实时性能。 因此，Google CRE 团队和Evernote 都使用相同的性能仪表板。 这似乎是一个非常简单的观点，但已被证明是一种非常强大的方式来推动真正以客户为中心的行为。 因此，Google 不会收到通用的“Service X 运行缓慢”类型的通知，而是向我们提供更具体的环境通知。 例如，除了通用的“ GCP 负载平衡环境今天运行缓慢”之外，我们还会被告知此问题对 Evernote 的 SLO 造成 5％ 的影响。 这种关系还可以帮助 Google 内部的团队，他们可以了解他们的行为和决策如何影响客户。

这种双向关系也为我们提供了一个非常有效的框架来支持重大事件。 大多数情况下，P1-P5 [Ticket](https://en.wikipedia.org/wiki/Ticket_(IT_security)) 和常规支持渠道的通常模式运作良好，使我们能够保持良好的服务并与 Google 建立良好的关系。 但我们都知道，有时P1 Ticket（“对我们的业务产生重大影响”）是不够的 - 整个服务上线的时间和您面临的扩展业务影响。

在这些时候，我们共享的 SLO 以及与 CRE 团队的关系得以实现。 我们有一个共同的理解，即如果 SLO 影响足够高，双方都会将问题视为具有特殊处理的 P1 Ticket。 很多时候，这意味着 Evernote 和 Google 的 CRE 团队在共享会议桥上迅速动员起来。 Google CRE 团队监控我们共同定义和商定的 SLO，使我们能够在优先级和适当响应方面保持同步。

### 当前状态

在积极使用 SLO 大约九个月之后，Evernote 已经在其SLO实践的第 3 版中。 下一版本的 SLO 将从我们简单的正常运行时间 SLO 开始。 我们计划开始探测单个 API 调用并考虑客户端的指标/性能视图，以便我们更好地表示用户 QoS。

通过提供标准和定义的 QoS 测量方法，SLO 允许 Evernote 更好地关注我们的服务运行方式。 我们现在可以在内部和谷歌之间进行数据驱动的对话，了解停机的影响，这使我们能够推动服务改进，最终建立更有效的支持团队和更快乐的客户。

## Home Depot 的 SLO 故事

作者：William Bonnell, The Home Depot

Home Depot（THD）是全球最大的家居装饰零售商：我们在北美拥有 2,200 多家商店，每家商店都拥有超过 35,000 种独特产品（并在线补充了超过 150 万种产品）。 我们的基础架构托管各种软件应用程序，每年支持近 400,000 名员工，处理超过 15 亿的客户交易。 这些商店与全球供应链和电子商务网站紧密集成，每年访问量超过 20 亿次。

在最近对我们旨在提高软件开发速度和质量的操作方法的更新中，THD 转向敏捷软件开发并改变了我们设计和管理软件的方式。 我们从支持大型单片软件包的集中支持团队转变为由小型独立运营的软件开发团队领导的微服务架构。 因此，我们的系统现在拥有更小的不断变化的软件块，这些软件也需要在堆栈中集成。

我们向微服务的转变得到了全栈所有权的新“自由和责任文化”的补充。 这种方法使开发人员可以自由地在需要时推送代码，同时也使他们共同负责其服务的运营。 对于这种共同所有权工作模式，运营和开发团队需要说一种促进问责制和跨越复杂性的共同语言：服务水平目标（SLO）。 相互依赖的服务需要知道如下信息：

- 您的服务有多可靠？ 它是为 3 个 9s，3 个半个 9s，还是 4 个 9s（或更好）构建的？ 有计划的停机时间吗？
- 在上限我可以期待什么样的延迟？
- 你能处理我要发送的请求量吗？ 你怎么处理超载？ 您的服务是否随着时间的推移实现了 SLO？

如果每项服务都能为这些问题提供透明和一致的答案，那么团队就可以清楚地了解他们的依赖关系，从而实现更好的沟通，增强团队之间的信任和责任感。

### SLO 文化项目

在我们的服务模式开始转变之前，Home Depot 没有 SLO 的文化。 监控工具和仪表板很多，但分布在各处，并且不会随着时间的推移跟踪数据。 我们并不总是能够在给定停机的根源上查明服务。 通常，我们开始在面向用户的服务中进行故障排除，然后向后工作直到我们发现问题，浪费了无数个小时。 如果服务需要计划停机时间，其依赖服务会感到惊讶。 如果一个团队需要建立一个三年半的 9s 服务，他们就不会知道他们有严格依赖的服务能否以更好的正常运行时间（4 个 9）来支持他们。 这些断开连接导致我们的软件开发和运维团队之间的混乱和失望。

我们需要通过建立 SLO 的共同文化来解决这些问题。 这样做需要一个影响人员，流程和技术的总体战略。 我们的努力跨越了四个方面：

*常见的白话*

在 THD 的上下文中定义 SLO。 定义如何以一致的方式测量它们。


*福音主义*

> 在整个公司传播这个词。
> - 创建培训材料以销售 SLO 的重要性，整个公司的路演，内部博客以及T恤和贴纸等宣传材料。
> - 争取一些早期采用者来实施 SLO 并向其他人展示其价值。
> - 建立一个吸引人的首字母缩略词（VALET;稍后讨论）以帮助传播这个想法。
> - 创建培训计划（FiRE 学院：可靠性工程基础），培训开发人员了解 SLO 和其他可靠性概念。<sup>2</sup>
>>  2 培训选项包括一小时的入门培训，半天的研讨会，以及成熟的 SRE 团队为期四周的沉浸式培训，以及毕业典礼和 FiRE 徽章。

*自动化*

> 为了减少采用的摩擦，实施度量收集平台以自动收集部署到生产的任何服务的服务级别指示器。 这些 SLIs 以后可以更容易地转换为 SLOs。

*激励*

> 为所有开发经理制定年度目标，为其服务设置和衡量 SLO。

建立一个共同的白话是让每个人都在同一页面上的关键。 我们还希望保持这个框架尽可能简单，以帮助这个想法更快地传播。 为了开始，我们仔细研究了我们在各种服务中监控的指标，并发现了一些模式。 每项服务都会监控某种形式的流量，延迟，错误和利用率指标，这些指标与 Google SRE 的[四个黄金信号](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/#xref_monitoring_golden-signals)密切相关。 此外，许多服务都可以从错误中明显监控正常运行时间或可用性。 不幸的是，所有指标类别都受到不一致的监控，命名不同或数据不足。

我们的服务都没有 SLO。 我们的生产系统与面向客户的 SLO 最接近的指标是支持票据。 我们测量部署到我们商店的应用程序可靠性的主要（通常也是唯一）方式是跟踪内部支持台收到的支持呼叫数量。

### 我们的第一套 SLO

我们无法为可以测量的系统的每个方面创建 SLO，因此我们必须决定哪些指标或 SLI 也应该具有 SLO。

#### API 调用的可用性和延迟

我们决定每个微服务必须具有其他微服务调用的 API 调用的可用性和延迟 SLO。 例如，Cart 微服务称为 库存微服务。对于那些API调用，库存微服务发布了 SLO，Cart 微服务（以及需要库存的其他微服务）可以查询以确定库存微服务是否能满足其可靠性要求

#### 基础设施利用

THD 团队以不同方式衡量基础设施利用率，但最典型的衡量标准是一分钟粒度的实时基础设施利用率。出于几个原因，我们决定不设置利用率 SLO。首先，微服务并不过分关注这个指标 - 你的用户并不真正关心利用率，只要你可以处理流量，你的微服务上升，它快速响应，它不会抛出错误 ，你没有失去容量的危险。此外，我们即将迁移到云计算意味着利用率不会受到关注，因此成本计划会使容量规划蒙上阴影。（我们仍然需要监控利用率并执行容量规划，但我们不需要将其包含在我们的 SLO 框架中。）

#### 流量

由于 THD 还没有容量规划文化，我们需要软件和运维团队的机制来传达他们的服务可以处理的数量。流量很容易定义为对服务的请求，但我们需要决定是否应该跟踪每秒平均请求数，每秒峰值请求数或报告时间段内的请求数。我们决定跟踪所有这三项，并让每项服务选择最合适的指标。我们讨论是否为流量设置 SLO，因为此度量标准由用户行为决定，而不是我们可以控制的内部因素。最终，我们决定作为零售商，我们需要为黑色星期五这样的峰值调整服务规模，因此我们根据预期的峰值容量设置 SLO。

#### 延迟

我们让每个服务定义其 SLO 以确定延迟并确定最佳测量位置。我们唯一的要求是服务应该通过黑盒监控来补充我们常见的白盒性能监控，以捕获由网络或其他层（如在微服务之外失效的缓存和代理）引起的问题。我们还确定百分位数比算术平均值更合适。 至少，服务需要达到 90％ 的目标; 面向用户的服务的首选目标是第 95 百分位数和第 99 百分位数或者第 99 百分位数。

#### 错误

错误有点复杂。 由于我们主要处理 Web 服务，因此我们必须标准化构成错误的内容以及如何返回错误。 如果 Web 服务遇到错误，我们自然会对HTTP响应代码进行标准化：

- 服务不应表明 2xx 响应正文中的错误; 相反，它应该抛出 4xx 或 5xx。
- 由服务问题（例如，内存不足）引起的错误应该引发 5xx 错误。
- 客户端引起的错误（例如，发送格式错误的请求）应该抛出 4xx 错误。

经过深思熟虑，我们决定跟踪 4xx 和 5xx 错误，但仅使用 5xx 错误来设置 SLO。 与我们针对其他 SLO 相关元素的方法类似，我们将此维度保持为通用，以便不同的应用程序可以将其用于不同的上下文。 例如，除 HTTP 错误外，批处理服务的错误可能是未能处理的记录数。

#### Ticket

如前所述，[Ticket](https://en.wikipedia.org/wiki/Ticket_(IT_security)) 最初是我们评估大多数生产软件的主要方式。 由于历史原因，我们决定继续跟踪其他 SLOs 的 Ticket。 您可以将此指标视为类似于“软件操作级别”之类的内容。

#### VALET(选举)

我们将新的 SLO 概括为一个方便的首字母缩略词：VALET。

*量（流量）*

> 我的服务可以处理多少业务量？

*可用性*

> 我需要的时候是服务吗？

*潜伏*

> 我使用它时服务是否快速响应？

*错误*

> 我使用它时服务是否会抛出错误？

*Ticket*

> 该服务是否需要手动干预才能完成我的请求？

### 传播 SLOs 的福音

凭借易于记忆的首字母缩略词，我们开始向企业传播 SLO:

- 为什么 SLO 很重要
- SLO 如何支持我们的“自由和责任”文化
- 应该测量什么
- 如何处理结果
